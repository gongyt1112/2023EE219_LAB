{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from Quantmodel.Quant import FullyConnectedLayer, ReLULayer, SoftmaxLossLayer\n",
    "from Quantmodel.mnist_mlp_cpu import MNIST_MLP, build_mnist_mlp\n",
    "import numpy as np\n",
    "import struct\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(mlp):\n",
    "    pred_results = np.zeros([mlp.test_data.shape[0]])\n",
    "    for idx in range(int(np.ceil(mlp.test_data.shape[0]/mlp.batch_size))):\n",
    "        batch_images = mlp.test_data[idx*mlp.batch_size:(idx+1)*mlp.batch_size, :-1]\n",
    "        prob = mlp.forward(batch_images)\n",
    "        pred_labels = np.argmax(prob, axis=1)\n",
    "        pred_results[idx*mlp.batch_size:(idx+1)*mlp.batch_size] = pred_labels\n",
    "    if mlp.test_data.shape[0] % mlp.batch_size >0: \n",
    "        last_batch = mlp.test_data.shape[0]/mlp.batch_size*mlp.batch_size\n",
    "        batch_images = mlp.test_data[-last_batch:, :-1]\n",
    "        prob = mlp.forward(batch_images)\n",
    "        pred_labels = np.argmax(prob, axis=1)\n",
    "        pred_results[-last_batch:] = pred_labels\n",
    "    accuracy = np.mean(pred_results == mlp.test_data[:,-1])*100\n",
    "    print('Accuracy in test set: %f %%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the \"evaluate()\" to get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = build_mnist_mlp()\n",
    "evaluate(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_DIR = \"./mnist_data\"\n",
    "TRAIN_DATA = \"train-images-idx3-ubyte\"\n",
    "TRAIN_LABEL = \"train-labels-idx1-ubyte\"\n",
    "TEST_DATA = \"t10k-images-idx3-ubyte\"\n",
    "TEST_LABEL = \"t10k-labels-idx1-ubyte\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In FullConnectedLayer, calcualte the scale of input and quantize it into 8-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_data(param_dir):\n",
    "    print('loading data from ' + param_dir)\n",
    "    data = np.load(param_dir, allow_pickle=True).item()\n",
    "    quant_num_bits = 8\n",
    "    quantization_params = {\n",
    "        'w1': ('sw1', -2**(quant_num_bits-1), 2**(quant_num_bits-1)-1),\n",
    "        'b1': ('sb1', -2**(quant_num_bits-1), 2**(quant_num_bits-1)-1),\n",
    "        'w2': ('sw2', -2**(quant_num_bits-1), 2**(quant_num_bits-1)-1),\n",
    "        'b2': ('sb2', -2**(quant_num_bits-1), 2**(quant_num_bits-1)-1),\n",
    "        'w3': ('sw3', -2**(quant_num_bits-1), 2**(quant_num_bits-1)-1),\n",
    "        'b3': ('sb3', -2**(quant_num_bits-1), 2**(quant_num_bits-1)-1)\n",
    "    }\n",
    "\n",
    "    quantized_data = {}\n",
    "    for param, (scale_key, min_val, max_val) in quantization_params.items():\n",
    "        raw_data = data[param]\n",
    "        scale = data[scale_key]\n",
    "        #TODOï¼šquantize the weight and bias stored in .npy file\n",
    "        quantized_param = _________________________\n",
    "        quantized_data[param] = quantized_param\n",
    "        quantized_data[scale_key] = data[scale_key]\n",
    "\n",
    "    np.save('.\\Data\\8bitdata.npy', quantized_data)\n",
    "    print('Saving parameters to file :  .\\Data\\8bitdata.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(object):\n",
    "    def __init__(self, num_input, num_output):  \n",
    "        self.num_input = num_input\n",
    "        self.num_output = num_output\n",
    "        print('\\tFully connected layer with input %d, output %d.' % (self.num_input, self.num_output))\n",
    "    def forward(self, input ):  \n",
    "        #TODO: quantize the input into 8-bit, obtain the scale factor\n",
    "        self.scale = _________________________\n",
    "        self.input = _________________________\n",
    "        self.output = np.dot(self.input, self.weight) + self.bias \n",
    "        return self.output \n",
    "    def load_param(self, weight, bias, w_scale, b_scale):  \n",
    "        # Load the saved weight, bias, and their corresponding scales from file \"mlp-128-128-5-epoch.npy \"\n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "        self.w_scale = w_scale\n",
    "        self.b_scale = b_scale\n",
    "    def save_param(self):\n",
    "        #Save the required data\n",
    "        return self.weight, self.bias, self.w_scale, self.b_scale, self.scale\n",
    "\n",
    "class ReLULayer(object):\n",
    "    def __init__(self):\n",
    "        print('\\tReLU layer.')\n",
    "    def forward(self, input):  \n",
    "        self.input = input\n",
    "        #ReLU layer's forward propagation, compute the output result\n",
    "        output = np.maximum(0, self.input)\n",
    "        return output\n",
    "class SoftmaxLossLayer(object):\n",
    "    def __init__(self):\n",
    "        print('\\tSoftmax loss layer.')\n",
    "    def forward(self, input):  \n",
    "        # softmax 's forward propagation, compute the output result\n",
    "        input_max = np.max(input, axis=1, keepdims=True)\n",
    "        input_exp = np.exp(input - input_max)\n",
    "        self.prob = input_exp/(np.sum(input_exp, axis = 1, keepdims = True) )\n",
    "        return self.prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(object):  #New Net without FakeQuant layers\n",
    "    def __init__(self, batch_size=100, input_size=784, hidden1=90, hidden2=90, out_classes=10, lr=0.01, max_epoch=10, print_iter=100):\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden1 = hidden1\n",
    "        self.hidden2 = hidden2\n",
    "        self.out_classes = out_classes\n",
    "        self.lr = lr\n",
    "        self.max_epoch = max_epoch\n",
    "        self.print_iter = print_iter\n",
    "\n",
    "    def load_mnist(self, file_dir, is_images = 'True'):\n",
    "        # Read binary data\n",
    "        bin_file = open(file_dir, 'rb')\n",
    "        bin_data = bin_file.read()\n",
    "        bin_file.close()\n",
    "        # Analysis file header\n",
    "        if is_images:\n",
    "            # Read images\n",
    "            fmt_header = '>iiii'\n",
    "            magic, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, 0)\n",
    "        else:\n",
    "            # Read labels\n",
    "            fmt_header = '>ii'\n",
    "            magic, num_images = struct.unpack_from(fmt_header, bin_data, 0)\n",
    "            num_rows, num_cols = 1, 1\n",
    "        data_size = num_images * num_rows * num_cols\n",
    "        mat_data = struct.unpack_from('>' + str(data_size) + 'B', bin_data, struct.calcsize(fmt_header))\n",
    "        mat_data = np.reshape(mat_data, [num_images, num_rows * num_cols])\n",
    "        print('Load images from %s, number: %d, data shape: %s' % (file_dir, num_images, str(mat_data.shape)))\n",
    "        return mat_data\n",
    "    \n",
    "    def load_data(self):\n",
    "        # preprocess the images and labels of the training and testing data in the MNIST dataset.\n",
    "        print('Loading MNIST data from files...')\n",
    "        train_images = self.load_mnist(os.path.join(MNIST_DIR, TRAIN_DATA), True)\n",
    "        train_labels = self.load_mnist(os.path.join(MNIST_DIR, TRAIN_LABEL), False)\n",
    "        test_images = self.load_mnist(os.path.join(MNIST_DIR, TEST_DATA), True)\n",
    "        test_labels = self.load_mnist(os.path.join(MNIST_DIR, TEST_LABEL), False)\n",
    "        self.train_data = np.append(train_images, train_labels, axis=1)\n",
    "        self.test_data = np.append(test_images, test_labels, axis=1)\n",
    "\n",
    "    def build_model(self): \n",
    "        #build net model\n",
    "        # without FakeQuant layer\n",
    "        print('Building multi-layer perception model...')\n",
    "        self.fc1 = FullyConnectedLayer(self.input_size, self.hidden1)\n",
    "        self.relu1 = ReLULayer()\n",
    "        self.fc2 = FullyConnectedLayer(self.hidden1, self.hidden2)\n",
    "        self.relu2 = ReLULayer()\n",
    "        self.fc3 = FullyConnectedLayer(self.hidden2, self.out_classes)\n",
    "        self.softmax = SoftmaxLossLayer()\n",
    "        self.update_layer_list = [self.fc1, self.fc2, self.fc3]\n",
    "\n",
    "    def load_model(self, param_dir):\n",
    "        #load data for each layer\n",
    "        print('Loading parameters from file ' + param_dir)\n",
    "        params = np.load(param_dir, allow_pickle=True).item()\n",
    "        self.fc1.load_param(params['w1'], params['b1'], params['sw1'], params['sb1'])     \n",
    "        self.fc2.load_param(params['w2'], params['b2'], params['sw2'], params['sb2'])\n",
    "        self.fc3.load_param(params['w3'], params['b3'], params['sw3'], params['sb3'])\n",
    "\n",
    "    def save_model(self, param_dir):\n",
    "        #save layer's data\n",
    "        #TODO: need save 5 parammeters\n",
    "        print('Saving parameters to file ' + param_dir)\n",
    "        params = {}\n",
    "        _________________________= self.fc1.save_param()\n",
    "        _________________________ = self.fc2.save_param()\n",
    "        _________________________ = self.fc3.save_param()\n",
    "        np.save(param_dir, params)\n",
    "    def forward(self, input):  \n",
    "        h1 = self.fc1.forward(input)\n",
    "        h1 = self.relu1.forward(h1)\n",
    "        h2 = self.fc2.forward(h1)\n",
    "        h2 = self.relu2.forward(h2)\n",
    "        h3 = self.fc3.forward(h2)\n",
    "        prob = self.softmax.forward(h3)\n",
    "        return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we use quantized weight and bias to get scale of activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Net():  \n",
    "    h1, h2, e =128, 128, 5#10\n",
    "    mlp = Net(hidden1=h1, hidden2=h2, max_epoch=e) \n",
    "    mlp.load_data()\n",
    "    mlp.build_model()\n",
    "    mlp.load_model('.\\Data\\8bitData.npy')     #load the quantized data into model\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_data('.\\Data\\mlp-128-128-5-epoch.npy')\n",
    "mlp = build_Net()\n",
    "evaluate(mlp)\n",
    "mlp.save_model('.\\Data\\\\answer.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained quantized weights, quantized biases, and the scaling factor for activations, we can load this data into the MLP network for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer2(object):\n",
    "    def __init__(self, num_input, num_output): \n",
    "        self.num_input = num_input\n",
    "        self.num_output = num_output\n",
    "        print('\\tFully connected layer with input %d, output %d.' % (self.num_input, self.num_output))\n",
    "    def forward(self, input ):  \n",
    "        #TODO: compared with FullyConnectedLayer, this layer need to use saved sacle to quantize input\n",
    "        self.input = _________________________\n",
    "        self.output = np.dot(self.input, self.weight) + self.bias \n",
    "        return self.output\n",
    "    def load_param(self, weight, bias, w_scale, b_scale, sa): \n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "        self.w_scale = w_scale\n",
    "        self.b_scale = b_scale\n",
    "        self.sa = sa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(object):\n",
    "    def __init__(self, batch_size=100, input_size=784, hidden1=90, hidden2=90, out_classes=10, lr=0.01, max_epoch=10, print_iter=100):\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden1 = hidden1\n",
    "        self.hidden2 = hidden2\n",
    "        self.out_classes = out_classes\n",
    "        self.lr = lr\n",
    "        self.max_epoch = max_epoch\n",
    "        self.print_iter = print_iter\n",
    "\n",
    "    def load_mnist(self, file_dir, is_images = 'True'):\n",
    "        # Read binary data\n",
    "        bin_file = open(file_dir, 'rb')\n",
    "        bin_data = bin_file.read()\n",
    "        bin_file.close()\n",
    "        # Analysis file header\n",
    "        if is_images:\n",
    "            # Read images\n",
    "            fmt_header = '>iiii'\n",
    "            magic, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, 0)\n",
    "        else:\n",
    "            # Read labels\n",
    "            fmt_header = '>ii'\n",
    "            magic, num_images = struct.unpack_from(fmt_header, bin_data, 0)\n",
    "            num_rows, num_cols = 1, 1\n",
    "        data_size = num_images * num_rows * num_cols\n",
    "        mat_data = struct.unpack_from('>' + str(data_size) + 'B', bin_data, struct.calcsize(fmt_header))\n",
    "        mat_data = np.reshape(mat_data, [num_images, num_rows * num_cols])\n",
    "        print('Load images from %s, number: %d, data shape: %s' % (file_dir, num_images, str(mat_data.shape)))\n",
    "        return mat_data\n",
    "    \n",
    "    \n",
    "    def load_data(self):\n",
    "\n",
    "        print('Loading MNIST data from files...')\n",
    "        train_images = self.load_mnist(os.path.join(MNIST_DIR, TRAIN_DATA), True)\n",
    "        train_labels = self.load_mnist(os.path.join(MNIST_DIR, TRAIN_LABEL), False)\n",
    "        test_images = self.load_mnist(os.path.join(MNIST_DIR, TEST_DATA), True)\n",
    "        test_labels = self.load_mnist(os.path.join(MNIST_DIR, TEST_LABEL), False)\n",
    "        self.train_data = np.append(train_images, train_labels, axis=1)\n",
    "        self.test_data = np.append(test_images, test_labels, axis=1)\n",
    "\n",
    "    def build_model(self):  \n",
    "        print('Building multi-layer perception model...')\n",
    "        self.fc1 = FullyConnectedLayer2(self.input_size, self.hidden1)\n",
    "        self.relu1 = ReLULayer()\n",
    "        self.fc2 = FullyConnectedLayer2(self.hidden1, self.hidden2)\n",
    "        self.relu2 = ReLULayer()\n",
    "        self.fc3 = FullyConnectedLayer2(self.hidden2, self.out_classes)\n",
    "        self.softmax = SoftmaxLossLayer()\n",
    "        self.update_layer_list = [self.fc1, self.fc2, self.fc3]\n",
    "\n",
    "    def load_model(self, param_dir):\n",
    "        #compared the previous load_model, we load a new parameter sa\n",
    "        print('Loading parameters from file ' + param_dir)\n",
    "        params = np.load(param_dir, allow_pickle=True).item()\n",
    "        self.fc1.load_param(params['w1'], params['b1'], params['sw1'], params['sb1'], params['sa1'])     \n",
    "        self.fc2.load_param(params['w2'], params['b2'], params['sw2'], params['sb2'], params['sa2'])\n",
    "        self.fc3.load_param(params['w3'], params['b3'], params['sw3'], params['sb3'], params['sa3'])\n",
    "    def forward(self, input):  \n",
    "        h1 = self.fc1.forward(input)\n",
    "        h1 = self.relu1.forward(h1)\n",
    "        h2 = self.fc2.forward(h1)\n",
    "        h2 = self.relu2.forward(h2)\n",
    "        h3 = self.fc3.forward(h2)\n",
    "        prob = self.softmax.forward(h3)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_Net2():  \n",
    "    h1, h2, e =128, 128, 5#10\n",
    "    mlp = Net2(hidden1=h1, hidden2=h2, max_epoch=e) \n",
    "    mlp.load_data()\n",
    "    mlp.build_model()\n",
    "    mlp.load_model('.\\Data\\\\answer.npy')     #load the quantized data into model\n",
    "    return mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = build_Net2()\n",
    "evaluate(mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Weights and Bias\n",
    "Plot histograms of the weights and bias stored in .npy file. Record any observations you make about the distribution of the values and report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD YOUR CODE HERE to plot distributions of weights of the original NN model. Add them to the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus : Lower precision\n",
    "Try to quantize into lower bits. Finsh bonus in a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d2bc9c231614f70288861d8c0bdd07a7fc891577a3f08fd712722d12cfb5982"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
